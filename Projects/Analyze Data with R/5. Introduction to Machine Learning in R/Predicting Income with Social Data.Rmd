---
title: "Predicting Income with Social Data"
output: html_notebook
date: "`r format(Sys.time(), '%d %B, %Y')`"
---
The Panel Survey of Income Data is the longest running longitudinal household survey in the world. Survey responses related to social, economic, and health outcomes have been collected from the families and their descendants since 1968. This dataset is widely used by social scientists to investigate the relationship between individual characteristics, like gender or age, and broader socioeconomic outcomes like education achievement and lifetime income. In this project, you’ll have the chance to use PSID data and linear regression to predict the labor-derived income of survey respondents based on the following set of variables:

- `gender`: the gender, female-identifying, male-identifying, or other, of a respondent
- `age`: the age of the respondent
- `married`: the marital status, unmarried, married, or divorced, of a respondent
- `employed`: the employment status of the respondent at the time of survey collection
- `educated_in_us`: whether the respondent went to primary school in the United Statues
- `highest_degree`: the highest educational degree obtained by the respondent
- `education_years`: the total number of years of formal education completed by the respondent
- `labor_income`: the yearly income earned by the respondent from a salary or hourly employment

Unlike other data science methods, **linear regression models will allow us to not only predict the value of a respondent’s income, but provide information on how a variable impacts respondent income**. Let’s dive into the social patterns that underlay Americans’ incomes!


### Clean and check data assumptions
```{r message=FALSE, warning=FALSE}
# load packages and data
library(ggplot2)
library(dplyr)
library(modelr)
```

```{r Import .txt file and write to csv, eval=FALSE}
# Import .txt file in R
psid_2017 = read.table("psid_2017.txt", sep=",", header=TRUE)

# storing this dataframe as csv file
write.csv(psid_2017, file = 'psid_2017.csv', row.names = FALSE)


psid <- read.csv("psid_2017.csv")

```

```{r}
# view data structure
print(str(psid))
```

### Plot age
```{r}
age_dist <- psid %>% ggplot(aes(x = age)) +
  geom_bar()
age_dist
```

```{r}

# filter to reasonable age group
psid_clean <- psid %>%
  filter(age < 18 | age > 75)
psid_clean

```

```{r}

# plot filtered age
filtered_age_dist <- psid_clean %>% ggplot(aes(x = age)) +
  geom_bar(aes(fill=highest_degree))
filtered_age_dist


# plot education
educ_dist <- psid_clean %>% ggplot(aes(education_years, education_years)) +
  geom_boxplot()
educ_dist
```

```{r}
# filter to reasonable education levels
psid_clean <- psid_clean %>%
  filter(education_years > 5, education_years < 25)
print(psid_clean)

# plot income
labor_income_plot <- psid_clean %>%
  ggplot(aes(education_years, labor_income)) + 
  geom_boxplot()
labor_income_plot

# view income summary statistics
summary(psid_clean$labor_income)
```

```{r}

# plot mean income by age
mean_income_by_age <- psid_clean%>%
  group_by(age) %>%
  summarise(mean_income = mean(labor_income)) %>%
  ggplot(aes(age, mean_income)) +
  geom_point() 
 
# view plot
mean_income_by_age
```
### Build model and assess fit
```{r}
# subset data points into train and test sets
set.seed(123)
data_sample <- sample(c(TRUE, FALSE), nrow(psid_clean), replace = T, prob = c(0.6,0.4))

# define train and test
train <- psid_clean[data_sample, ]
test <- psid_clean[!data_sample, ]
```

```{r}
# build model a simple linear model
model <- lm(labor_income ~ education_years, data = train)


# plot against LOESS model
plot <- train %>%
  ggplot(aes(x = education_years, y = labor_income)) +
  geom_point() +
  geom_smooth(method = "lm") +
  geom_smooth(se = FALSE, color = "red")
plot


# compute r-squared
r_sq <- summary(model)$r.squared * 100

# write out r-squared interpretation
sprintf("Based on a simple linear regression model, we have determined that %s percent of the variation in respondent income can be predicted by a respondent's education level.", r_sq)

```
### Build comparison model and analyze results
```{r}
# build second model
model_2 <- lm(labor_income ~ education_years + age + gender, data = train)

# compute r-squared
r_sq_2 <- summary(model_2)$r.squared * 100

# write out r-squared interpretation
sprintf("Based on a simple linear regression model, we have determined that %s percent of the variation in respondent income can be predicted by a respondent's education level, age and gender.", r_sq_2)
```

```{r}
# plot predictions versus observed
plot_2 <- test %>%
  add_predictions(model_2) %>%
  ggplot(aes(x = age, y = labor_income)) +
  geom_point() +
  geom_line(aes(y = pred), color = 'blue')

plot_2

# write out model results
summary(model_2)


# extract education coefficient
education_coefficent <- model_2$coefficients[2]

# write out coefficient interpretation
sprintf("Based on a multiple linear regression model of education, age, and gender, for every additional year of formal education, the average American resident's income increases by $%s.", education_coefficent)
```