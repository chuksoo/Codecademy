library(neuralnet)
library(NeuralNetTools)
library(xfun)
set.seed(440)
data <- read.csv("Q4_data.csv", header=TRUE)
summary(data)
# Check that no data is missing
apply(data,2,function(x) sum(is.na(x)))
# Train-test random splitting for linear model
index <- sample(1:nrow(data), round(0.75*nrow(data)))
train <- data[index,]
test <- data[-index,]
# Fitting linear model to the train dataset
lm.fit <- lm(Gas_prod~., data=train)
summary(lm.fit)
# Predicted data from linear model fit
pr.lm <- predict(lm.fit, test)
# Test MSE
MSE.lm <- sum((pr.lm - test$Gas_prod)^2)/nrow(test)
# Neural network fitting
# Scaling data for the Neural Network
maxs <- apply(data, 2, max)
mins <- apply(data, 2, min)
scaled <- as.data.frame(scale(data, center = mins, scale = maxs - mins))
# Train-test split
train_ <- scaled[index,]
test_ <- scaled[-index,]
# Training the neural network
n <- names(train_)
f <- as.formula(paste("Gas_prod ~", paste(n[!n %in% "Gas_prod"], collapse = " + ")))
neural_net <- neuralnet(f, data = train_, hidden = c(5,3), linear.output = T)
# Visual plot of the model
plot(neural_net)
# Prediction
pr.nn <- compute(neural_net, test_[,1:14])
# install knitr
install.packages("knitr")
# install the rmarkdown package
install.packages("rmarkdown")
# install ggplot for plotting
install.packages("ggplot2")
# install dplyr for data manipulation
install.packages("dplyr")
# install neuralnet for artificial neural network
install.packages("neuralnet")
install.packages("NeuralNetTools")
install.packages("neuralnet")
install.packages("NeuralNetTools")
# load libraries
library(knitr)
library(rmarkdown)
library(ggplot2)
library(dplyr)
library(neuralnet)
library(NeuralNetTools)
library(xfun)
set.seed(440)
data <- read.csv("Q4_data.csv", header=TRUE)
summary(data)
# Check that no data is missing
apply(data,2,function(x) sum(is.na(x)))
# Train-test random splitting for linear model
index <- sample(1:nrow(data), round(0.75*nrow(data)))
train <- data[index,]
test <- data[-index,]
# Fitting linear model to the train dataset
lm.fit <- lm(Gas_prod~., data=train)
summary(lm.fit)
# Predicted data from linear model fit
pr.lm <- predict(lm.fit, test)
# Test MSE
MSE.lm <- sum((pr.lm - test$Gas_prod)^2)/nrow(test)
# Neural network fitting
# Scaling data for the Neural Network
maxs <- apply(data, 2, max)
mins <- apply(data, 2, min)
scaled <- as.data.frame(scale(data, center = mins, scale = maxs - mins))
# Train-test split
train_ <- scaled[index,]
test_ <- scaled[-index,]
# Training the neural network
n <- names(train_)
f <- as.formula(paste("Gas_prod ~", paste(n[!n %in% "Gas_prod"], collapse = " + ")))
neural_net <- neuralnet(f, data = train_, hidden = c(5,3), linear.output = T)
# Visual plot of the model
plot(neural_net)
# Prediction
pr.nn <- compute(neural_net, test_[,1:14])
# Results from Neural Networks are normalized (scaled)
# Descaling for comparison
pr.nn_ <- pr.nn$net.result*(max(data$Gas_prod)-min(data$Gas_prod))+min(data$Gas_prod)
test.r <- (test_$Gas_prod)*(max(data$Gas_prod)-min(data$Gas_prod))+min(data$Gas_prod)
# Calculating MSE
MSE.nn <- sum((test.r - pr.nn_)^2)/nrow(test_)
# Prediction
pr.nn <- compute(neural_net, test_[,1:14])
# Results from Neural Networks are normalized (scaled)
# Descaling for comparison
pr.nn_ <- pr.nn$net.result*(max(data$Gas_prod)-min(data$Gas_prod))+min(data$Gas_prod)
test.r <- (test_$Gas_prod)*(max(data$Gas_prod)-min(data$Gas_prod))+min(data$Gas_prod)
# Calculating MSE
MSE.nn <- sum((test.r - pr.nn_)^2)/nrow(test_)
# Compare the two Mean Squared Errors (MSEs)
print(paste(MSE.lm, MSE.nn))
# Plot predictions
par(mfrow=c(1,2))
plot(test$Gas_prod, pr.nn_, col='red', main='Real vs predicted NN', pch=18, cex=0.7)
abline(0,1,lwd=2)
legend('bottomright', legend='NN', pch=18, col='red', bty='n')
plot(test$Gas_prod, pr.lm, col='blue', main='Real vs predicted lm', pch=18, cex=0.7)
abline(0,1,lwd=2)
legend('bottomright', legend='LM', pch=18, col='blue', bty='n', cex=.95)
# Compare predictions on the same plot
plot(test$Gas_prod, pr.nn_, col='red', main='Real vs predicted NN', pch=18, cex=0.7)
points(test$Gas_prod, pr.lm, col='blue', pch=18, cex=0.7)
abline(0,1,lwd=2)
legend('bottomright', legend=c('NN','LM'), pch=18, col=c('red','blue'))
# Neural net fitting
set.seed(440)
mydata <- read.csv("Q4_data.csv", header=TRUE)
#Normalizing the dataset
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
maxmindf <- as.data.frame(lapply(mydata, normalize))
# Display head of data
head(mydata)
# Display tail of data
tail(mydata)
# Training and Test Data
trainset <- maxmindf[1:312, ]
testset <- maxmindf[313:446, ]
# Neural Network Training
library(neuralnet)
nn <- neuralnet(Gas_prod ~ Perf_Int + Frac_vol + Proppant + N.frac +
Tubing.depth + Casing.depth + FTP + Choke.Size + SITHP +
SG_gas + Well_Type + Latitude + Long. + Acid, data=trainset,
hidden=c(3,2), linear.output=TRUE, threshold=0.01)
nn$result.matrix
# Visual plot of the model
plot(nn)
#Test the resulting output
temp_test <- subset(testset, select = c("Gas_prod", "Perf_Int", "Frac_vol",
"Proppant", "N.frac", "Tubing.depth",
"Casing.depth",  "FTP", "Choke.Size",
"SITHP", "SG_gas", "Well_Type", "Latitude",
"Long.", "Acid"))
head(temp_test)
nn.results <- compute(nn, temp_test)
#Comparison of Predicted to Actual
results <- data.frame(actual = testset$Gas_prod, prediction = nn.results$net.result)
results
#Testing The Accuracy Of The Model
Gas_prod <- trainset$Gas_prod
predicted = results$prediction * abs(diff(range(Gas_prod))) + min(Gas_prod)
actual = results$actual * abs(diff(range(Gas_prod))) + min(Gas_prod)
comparison = data.frame(predicted, actual)
deviation = ((actual-predicted)/actual)
comparison = data.frame(predicted, actual, deviation)
accuracy = 1-abs(mean(deviation))
accuracy
nn <- neuralnet(Gas_prod ~ Perf_Int + Frac_vol + Proppant + N.frac + Tubing.depth
+ Casing.depth + FTP + Choke.Size + SITHP + SG_gas + Well_Type
+ Latitude + Long. + Acid,data=trainset, hidden=c(5,2),
linear.output=TRUE, threshold=0.01)
nn$result.matrix
plot(nn)
#Test the resulting output
temp_test <- subset(testset, select = c("Gas_prod", "Perf_Int", "Frac_vol",
"Proppant", "N.frac", "Tubing.depth",
"Casing.depth",  "FTP", "Choke.Size",
"SITHP", "SG_gas", "Well_Type", "Latitude",
"Long.", "Acid"))
head(temp_test)
nn.results <- compute(nn, temp_test)
results <- data.frame(actual = testset$Gas_prod, prediction = nn.results$net.result)
results
#Testing The Accuracy Of The Model
predicted = results$prediction * abs(diff(range(Gas_prod))) + min(Gas_prod)
actual = results$actual * abs(diff(range(Gas_prod))) + min(Gas_prod)
comparison = data.frame(predicted,actual)
deviation = ((actual-predicted)/actual)
comparison = data.frame(predicted,actual,deviation)
accuracy = 1-abs(mean(deviation))
accuracy
# load libraries
library(knitr)
library(rmarkdown)
library(ggplot2)
library(dplyr)
library(neuralnet)
library(NeuralNetTools)
library(xfun)
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/', echo = TRUE)
# load libraries
library(knitr)
library(rmarkdown)
library(ggplot2)
library(dplyr)
library(neuralnet)
library(NeuralNetTools)
library(xfun)
# load libraries
library(knitr)
library(rmarkdown)
library(ggplot2)
library(dplyr)
library(neuralnet)
library(NeuralNetTools)
library(xfun)
set.seed(440)
data <- read.csv("Q4_data.csv", header=TRUE)
summary(data)
# Check that no data is missing
apply(data,2,function(x) sum(is.na(x)))
# Train-test random splitting for linear model
index <- sample(1:nrow(data), round(0.75*nrow(data)))
train <- data[index,]
test <- data[-index,]
# Fitting linear model to the train dataset
lm.fit <- lm(Gas_prod~., data=train)
summary(lm.fit)
# Predicted data from linear model fit
pr.lm <- predict(lm.fit, test)
# Test MSE
MSE.lm <- sum((pr.lm - test$Gas_prod)^2)/nrow(test)
# Neural network fitting
# Scaling data for the Neural Network
maxs <- apply(data, 2, max)
mins <- apply(data, 2, min)
scaled <- as.data.frame(scale(data, center = mins, scale = maxs - mins))
# Train-test split
train_ <- scaled[index,]
test_ <- scaled[-index,]
# Training the neural network
n <- names(train_)
f <- as.formula(paste("Gas_prod ~", paste(n[!n %in% "Gas_prod"], collapse = " + ")))
neural_net <- neuralnet(f, data = train_, hidden = c(5,3), linear.output = T)
# Training the neural network
n <- names(train_)
f <- as.formula(paste("Gas_prod ~", paste(n[!n %in% "Gas_prod"], collapse = " + ")))
neural_net <- neuralnet(f, data = train_, hidden = c(5,3), linear.output = T)
# Visual plot of the model
plot(neural_net)
# Prediction
pr.nn <- compute(neural_net, test_[,1:14])
# Results from Neural Networks are normalized (scaled)
# Descaling for comparison
pr.nn_ <- pr.nn$net.result*(max(data$Gas_prod)-min(data$Gas_prod))+min(data$Gas_prod)
test.r <- (test_$Gas_prod)*(max(data$Gas_prod)-min(data$Gas_prod))+min(data$Gas_prod)
# Calculating MSE
MSE.nn <- sum((test.r - pr.nn_)^2)/nrow(test_)
# Compare the two Mean Squared Errors (MSEs)
print(paste(MSE.lm, MSE.nn))
# Plot predictions
par(mfrow=c(1,2))
plot(test$Gas_prod, pr.nn_, col='red', main='Real vs predicted NN', pch=18, cex=0.7)
abline(0,1,lwd=2)
legend('bottomright', legend='NN', pch=18, col='red', bty='n')
plot(test$Gas_prod, pr.lm, col='blue', main='Real vs predicted lm', pch=18, cex=0.7)
abline(0,1,lwd=2)
legend('bottomright', legend='LM', pch=18, col='blue', bty='n', cex=.95)
# Compare predictions on the same plot
plot(test$Gas_prod, pr.nn_, col='red', main='Real vs predicted NN', pch=18, cex=0.7)
points(test$Gas_prod, pr.lm, col='blue', pch=18, cex=0.7)
abline(0,1,lwd=2)
legend('bottomright', legend=c('NN','LM'), pch=18, col=c('red','blue'))
# Neural net fitting
set.seed(440)
mydata <- read.csv("Q4_data.csv", header=TRUE)
#Normalizing the dataset
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
maxmindf <- as.data.frame(lapply(mydata, normalize))
# Display head of data
head(mydata)
# Display tail of data
tail(mydata)
# Training and Test Data
trainset <- maxmindf[1:312, ]
testset <- maxmindf[313:446, ]
# Neural Network Training
library(neuralnet)
nn <- neuralnet(Gas_prod ~ Perf_Int + Frac_vol + Proppant + N.frac +
Tubing.depth + Casing.depth + FTP + Choke.Size + SITHP +
SG_gas + Well_Type + Latitude + Long. + Acid, data=trainset,
hidden=c(3,2), linear.output=TRUE, threshold=0.01)
nn$result.matrix
# Visual plot of the model
plot(nn)
#Test the resulting output
temp_test <- subset(testset, select = c("Gas_prod", "Perf_Int", "Frac_vol",
"Proppant", "N.frac", "Tubing.depth",
"Casing.depth",  "FTP", "Choke.Size",
"SITHP", "SG_gas", "Well_Type", "Latitude",
"Long.", "Acid"))
head(temp_test)
nn.results <- compute(nn, temp_test)
#Comparison of Predicted to Actual
results <- data.frame(actual = testset$Gas_prod, prediction = nn.results$net.result)
results
#Testing The Accuracy Of The Model
Gas_prod <- trainset$Gas_prod
predicted = results$prediction * abs(diff(range(Gas_prod))) + min(Gas_prod)
actual = results$actual * abs(diff(range(Gas_prod))) + min(Gas_prod)
comparison = data.frame(predicted, actual)
deviation = ((actual-predicted)/actual)
comparison = data.frame(predicted, actual, deviation)
accuracy = 1-abs(mean(deviation))
accuracy
nn <- neuralnet(Gas_prod ~ Perf_Int + Frac_vol + Proppant + N.frac + Tubing.depth
+ Casing.depth + FTP + Choke.Size + SITHP + SG_gas + Well_Type
+ Latitude + Long. + Acid,data=trainset, hidden=c(5,2),
linear.output=TRUE, threshold=0.01)
nn$result.matrix
plot(nn)
#Test the resulting output
temp_test <- subset(testset, select = c("Gas_prod", "Perf_Int", "Frac_vol",
"Proppant", "N.frac", "Tubing.depth",
"Casing.depth",  "FTP", "Choke.Size",
"SITHP", "SG_gas", "Well_Type", "Latitude",
"Long.", "Acid"))
head(temp_test)
nn.results <- compute(nn, temp_test)
results <- data.frame(actual = testset$Gas_prod, prediction = nn.results$net.result)
results
#Testing The Accuracy Of The Model
predicted = results$prediction * abs(diff(range(Gas_prod))) + min(Gas_prod)
actual = results$actual * abs(diff(range(Gas_prod))) + min(Gas_prod)
comparison = data.frame(predicted,actual)
deviation = ((actual-predicted)/actual)
comparison = data.frame(predicted,actual,deviation)
accuracy = 1-abs(mean(deviation))
accuracy
# load libraries
# Create vector of packages
project_packages <- c("knitr", "rmarkdown", "tidyverse", "data.table", "matrixStats", "fields", "plyr", "ggplot2", "nls2", "purrr", "nlstools", "nlme", "plotly", "ggthemes", "minpack.lm", "forecast", "tseries", "dplyr", "extrafont")
lapply(project_packages, require, character.only = TRUE)    # load multiple packages
set.seed(500)
prod_data <- read.csv("midlandbasinoil.csv")
install.packages("shiny")
install.packages("learnr")
x <- c(15,8,9,15,12,13,2,15,13,8,13,6,7)
Mode(x)
# Load libraries
library(readr)
library(dplyr)
library(DescTools)
x <- c(15,8,9,15,12,13,2,15,13,8,13,6,7)
Mode(x)
x <- c(15,8,9,15,12,13,2,15,13,8,13,6,7)
mean(x)
median(x)
Mode(x)
x <- c(10,13,7,10,5,15)
mean(x)
median(x)
Mode(x)
knitr::opts_chunk$set(echo = TRUE)
sample(x = 1:6, size = 2, replace = TRUE)
sample(x = 1:6, size = 2, replace = TRUE)
sample(x = 1:6, size = 2, replace = TRUE)
sample(x = 1:6, size = 2, replace = TRUE)
# define a function
function_name <- function(parameter_1, parameter_2, ....) {
# do something with parameter_1 and parameter_2
return(some_value)
}
apply(<data_structure>, margin_value, function_name)
# define a function
function_name <- function(parameter_1, parameter_2, ....) {
# do something with parameter_1 and parameter_2
return(some_value)
}
apply(<data_structure>, margin_value, function_name)
# define a function
function_name <- function(parameter_1, parameter_2, ....) {
# do something with parameter_1 and parameter_2
return(some_value)
}
apply(<data_structure>, margin_value, function_name)
# define a function
function_name <- function(parameter_1, parameter_2, ....) {
# do something with parameter_1 and parameter_2
return(some_value)
}
apply(data_structure, margin_value, function_name)
knitr::opts_chunk$set(echo = TRUE)
my_string_vector <- c("this", "is", "an", "example", "vector")
my_string_vector[3] # returns "an"
my_boolean_vector <- c(TRUE, FALSE, FALSE)
my_numerical_vector <- c(0.4, 0.9, 1, 0.45, 1.2, 0.33)
# R will force the same type even if you input different types to c()
my_vector <- c("word", 45, 12, FALSE)
# result: a vector of strings "word" "45" "12" "FALSE"
my_list <- list("Elephant", FALSE, 900, 80.3, list("pencil", "pens"))
my_list[[4]] # returns 80.3
my_longer_list <- list(misc = my_list, notes = c("g", "b", "d", "g"))
my_longer_list[[1]]
# returns the contents of my_list
my_longer_list$misc
# returns the contents of my_list
my_longer_list$notes
# returns "g" "b" "d" "g"
# will create a 3-by-3 matrix with the vectors being filled column-wise (default)
my_matrix <- matrix(c("a", "b", "e", "k", "e", "w", "g", "x", "t"), nrow = 3, ncol = 3)
# result:
# "a" "k" "g"
# "b" "e" "x"
# "e" "w" "t"
single_element <- my_matrix[1, 3]
# returns "g"
second_row <- my_matrix[2,]
# returns: "b" "e" "x"
second_col <- my_matrix[,2]
# returns: "k" "e" "w"
if (condition_to_check) {
# execute code and don't check any more conditions
} else if (other_condition_to_check & and_this_condition_to_check) {
# execute code only if both are true and don't check any more conditions
} else if (either_this_condition | or_this_condition ) {
# execute code if either condition is true and don't go to else
} else {
# the default code if none of the conditions above are true
}
sample(x = 1:6, size = 2, replace = TRUE)
unlink("C:/Users/hotty/Desktop/Cheat Sheet for AI, ML, Data Science, Python and R/Programming in R_cache", recursive = TRUE)
knitr::opts_chunk$set(echo = TRUE)
my_string_vector <- c("this", "is", "an", "example", "vector")
my_string_vector[3] # returns "an"
my_boolean_vector <- c(TRUE, FALSE, FALSE)
my_numerical_vector <- c(0.4, 0.9, 1, 0.45, 1.2, 0.33)
# R will force the same type even if you input different types to c()
my_vector <- c("word", 45, 12, FALSE)
# result: a vector of strings "word" "45" "12" "FALSE"
my_list <- list("Elephant", FALSE, 900, 80.3, list("pencil", "pens"))
my_list[[4]] # returns 80.3
my_longer_list <- list(misc = my_list, notes = c("g", "b", "d", "g"))
my_longer_list[[1]]
# returns the contents of my_list
my_longer_list$misc
# returns the contents of my_list
my_longer_list$notes
# returns "g" "b" "d" "g"
# will create a 3-by-3 matrix with the vectors being filled column-wise (default)
my_matrix <- matrix(c("a", "b", "e", "k", "e", "w", "g", "x", "t"), nrow = 3, ncol = 3)
# result:
# "a" "k" "g"
# "b" "e" "x"
# "e" "w" "t"
single_element <- my_matrix[1, 3]
# returns "g"
second_row <- my_matrix[2,]
# returns: "b" "e" "x"
second_col <- my_matrix[,2]
# returns: "k" "e" "w"
sample(x = 1:6, size = 2, replace = TRUE)
getwd()
setwd("C:/Users/hotty/Desktop/Codecademy Dev/Codecademy/Projects/Analyze Data with R")
getwd()
library(ggplot2)
library(ggthemes)
install.packages(c("ggplot2", "ggthemes"))
qplot
library('ggplot2')
qplot
x3 <- c(0, 1, 1, 2, 2, 2, 3, 3, 4)
qplot(x3, binwidth = 1)
replicate(3, 1 + 1)
replicate(10, roll())
roll <- function() {
die <- 1:6
dice <- sample(die, size = 2, replace = TRUE)
sum(dice)
}
replicate(10, roll())
replicate(10, roll())
qplot(replicate(10, roll()), binwidth = 0.5)
qplot(replicate(10, roll()), binwidth = 0)
qplot(replicate(10, roll()), binwidth = 1)
rolls <- replicate(10000, roll())
qplot(rolls, binwidth = 1)
?sample
roll <- function() {
die <- 1:6
dice <- sample(die, size = 2, replace = TRUE,
prob = c(1/8, 1/8, 1/8, 1/8, 1/8, 3/8))
sum(dice)
}
rolls <- replicate(10000, roll())
qplot(rolls, binwidth = 1)
rolls <- replicate(10000, roll())
qplot(rolls, binwidth = 1)
rolls <- replicate(10000, roll())
qplot(rolls, binwidth = 1)
deck <- read.csv("C:/Users/hotty/Desktop/Codecademy Dev/Codecademy/Projects/Data/deck.txt")
View(deck)
head(deck)
write.csv(deck, file = "card_deck.csv", row.names = FALSE)
deck2 <- shuffle(deck)
random <- sample(1:52, size = 52)
deck[random, ]
deck2 <- shuffle(deck)
shuffle <- function(deck) {
random <- sample(1:52, size = 52)
deck[random, ]
}
deck2 <- shuffle(deck)
deck2
deck2$face == 'spades'
sum(deck2$face == 'spades')
